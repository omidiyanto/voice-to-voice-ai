<!DOCTYPE html>
<html>
<head>
    <title>NOVA - Neural-Orchestrated Voice Assistant</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='style.css') }}">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/atom-one-dark.min.css">
    <link rel="icon" type="image/png" href="{{ url_for('static', filename='logo.png') }}">
    <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        #overlay {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: #0a0a0a;
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 9999;
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <div id="overlay" style="display:none;"></div>

    <div class="container">
        <div class="header">
            <div class="logo">
                <img class="logo-image" src="{{ url_for('static', filename='logo.png') }}" alt="NOVA Logo">
            </div>
            <div class="status-container">
                <div class="status-bullet" id="statusIndicator"></div>
                <div id="statusText">Initializing...</div>
            </div>
        </div>

        <div class="audio-visualizer">
            <div class="bar"></div>
            <div class="bar"></div>
            <div class="bar"></div>
            <div class="bar"></div>
            <div class="bar"></div>
        </div>

        <div class="chat-container" id="chatContainer"></div>

        <audio id="ttsAudio"></audio>

        <footer style="margin-top: 20px;">
            <a href="https://github.com/omidiyanto/voice-to-voice-ai" target="_blank" class="github-link">
                <i class="fab fa-github"></i>
            </a>
            <div class="author">Developed by O. Midiyanto</div>
        </footer>
    </div>

    <script>
        const overlay = document.getElementById('overlay');
        const statusIndicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');
        const chatContainer = document.getElementById('chatContainer');
        const ttsAudio = document.getElementById('ttsAudio');
        let isProcessing = false;
        let recognition;
        let manualReconnect = false;

        // Initialize Marked with options
        marked.setOptions({
            breaks: true,
            sanitize: true,
            highlight: function(code, lang) {
                const language = hljs.getLanguage(lang) ? lang : 'plaintext';
                return hljs.highlight(code, { language }).value;
            }
        });

        function initSpeech() {
            if (recognition) {
                recognition.onstart = null;
                recognition.onresult = null;
                recognition.onerror = null;
                recognition.onend = null;
                try {
                    recognition.stop();
                } catch(e) {}
            }

            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (SpeechRecognition) {
                recognition = new SpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = 'en-US';
                recognition.maxAlternatives = 1;

                recognition.onstart = () => {
                    statusText.textContent = "Listening...";
                    statusIndicator.classList.add('listening');
                };

                recognition.onresult = async (event) => {
                    if (isProcessing) return;

                    const transcript = Array.from(event.results)
                        .slice(-1)[0][0].transcript;

                    if (event.results[event.results.length - 1].isFinal) {
                        isProcessing = true;
                        statusText.textContent = "Processing...";
                        statusIndicator.classList.remove('listening');
                        statusIndicator.classList.add('processing');

                        try {
                            addMessage(transcript, 'user');

                            const response = await fetch('/chat', {
                                method: 'POST',
                                headers: {'Content-Type': 'application/json'},
                                body: JSON.stringify({message: transcript})
                            });

                            const data = await response.json();
                            if(data.status === 'success') {
                                addMessage(data.response, 'assistant');
                                if(data.audio && data.audio.length > 0) {
                                    ttsAudio.src = "data:audio/mpeg;base64," + data.audio;
                                    ttsAudio.play().catch(console.error);

                                    ttsAudio.onended = () => {
                                        isProcessing = false;
                                        statusIndicator.classList.remove('processing');
                                        statusText.textContent = "Listening...";
                                        if (!manualReconnect) recognition.start();
                                    };
                                } else {
                                    isProcessing = false;
                                    statusIndicator.classList.remove('processing');
                                    statusText.textContent = "Listening...";
                                    if (!manualReconnect) recognition.start();
                                }
                            }
                        } catch (error) {
                            console.error('Error:', error);
                            isProcessing = false;
                            statusIndicator.classList.remove('processing');
                            statusText.textContent = "Listening...";
                            if (!manualReconnect) recognition.start();
                        }
                    }
                };

                recognition.onerror = (event) => {
                    console.error('Recognition error:', event.error);
                    manualReconnect = true;
                    recognition.stop();
                    statusText.textContent = "Reconnecting...";
                    setTimeout(() => {
                        manualReconnect = false;
                        initSpeech();
                    }, 2000);
                };

                recognition.onend = () => {
                    if (manualReconnect) return;
                    if (!isProcessing) {
                        statusText.textContent = "Starting...";
                        setTimeout(() => {
                            try {
                                recognition.start();
                            } catch(e) {
                                console.log('Recognition start error:', e);
                                initSpeech();
                            }
                        }, 500);
                    }
                };

                try {
                    recognition.start();
                } catch(e) {
                    console.error('Initial start error:', e);
                    statusText.textContent = "Error starting, retrying...";
                    setTimeout(initSpeech, 1000);
                }
            } else {
                statusText.textContent = "Browser tidak mendukung Speech Recognition. Gunakan Chrome, Edge, atau browser lain yang mendukung fitur ini.";
            }
        }

        function addMessage(text, role) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            
            messageDiv.innerHTML = `
                <div class="message-content">
                    <div class="message-icon">
                        ${role === 'user' ? '<i class="fas fa-user"></i>' : '<i class="fas fa-robot"></i>'}
                    </div>
                    <div class="bubble"></div>
                </div>
            `;

            const bubble = messageDiv.querySelector('.bubble');
            
            if (role === 'assistant') {
                bubble.innerHTML = marked.parse(text);
                
                // Apply syntax highlighting after DOM update
                setTimeout(() => {
                    messageDiv.querySelectorAll('pre code').forEach(block => {
                        hljs.highlightElement(block);
                    });
                }, 0);
            } else {
                bubble.textContent = text;
            }

            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        function showMicPermissionPrompt() {
            Swal.fire({
                title: 'Microphone Access Required',
                text: 'This app needs your microphone access permission to let you talk with NOVA.',
                icon: 'info',
                background: '#0a0a0a',
                color: 'white',
                iconColor: '#00ff9d',
                confirmButtonColor: '#00ff9d',
                confirmButtonText: 'Allow Microphone Access',
                customClass: {
                    confirmButton: 'swal2-text-black'
                }
            }).then((result) => {
                if (result.isConfirmed) {
                    overlay.style.display = 'none';
                    initSpeech();
                    if (typeof AudioContext !== 'undefined') {
                        const audioCtx = new AudioContext();
                        if (audioCtx.state === 'suspended') {
                            audioCtx.resume();
                        }
                    }
                }
            });
        }

        window.onload = () => {
            showMicPermissionPrompt();
        };

        document.addEventListener('contextmenu', function (e) {
            e.preventDefault();
        });
    </script>
</body>
</html>